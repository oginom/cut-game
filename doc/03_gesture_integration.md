# Phase 3: ジェスチャー操作の統合 - 詳細実装計画

## 概要

Phase 3では、Phase 1で実装したハンドトラッキング機能とPhase 2で実装したゲームコア機能を統合し、手のジェスチャーでロープを切断できるようにします。

## 目標

- ピースサイン（Vサイン）の検出
- V閉じ動作の検出
- 手の3Dモデル（カニの手）表示
- ジェスチャーによるロープ切断

## Step 3.1: ジェスチャー認識の実装

### 目的

手の形状（ピースサイン）と動作（V閉じ）を検出するロジックを実装します。

### タスク詳細

1. **型定義ファイルの作成**
   - `src/types/gesture.ts`を作成
   - ジェスチャーの種類（none, victory, other）
   - ジェスチャーイベント（ジェスチャーの変化、手の種類）
   - ジェスチャー設定

2. **MediaPipe GestureRecognizerの導入**
   - `@mediapipe/tasks-vision`の`GestureRecognizer`を使用
   - HandLandmarkerの代わりに、またはHandLandmarkerと並行して使用
   - 事前学習済みモデルで以下のジェスチャーを認識:
     - `Victory`: ピースサイン（Vサイン）
     - `Closed_Fist`: グー
     - `Open_Palm`: パー
     - `Pointing_Up`: 人差し指を立てる
     - `Thumb_Up`: サムズアップ
     - `Thumb_Down`: サムズダウン
     - `ILoveYou`: 親指+人差し指+小指

3. **GestureTrackerコンポーネントの実装**
   - `src/components/camera/GestureTracker.ts`を作成
   - MediaPipe GestureRecognizerの初期化
   - トラッキングループの実装（HandTrackerと同様）
   - ジェスチャーの検出と状態管理
   - コールバックによるジェスチャーイベント通知

4. **ジェスチャー判定ロジック**
   - **ピースサイン（開いた状態）**: `Victory`ジェスチャーを検出
   - **V閉じ動作**: `Victory`から別のジェスチャー（`Victory`以外）への遷移を検出
     - チョキを閉じた形は事前定義ジェスチャーに含まれないため、`Victory`以外になったら「閉じた」と判定
     - ユーザーが手を閉じる（グー）、開く（パー）、または他の形にすれば切断アクションが発動
   - 左右の手を独立して認識
   - 各手の前回のジェスチャー状態を保持して遷移を検出

5. **TrackingManagerの更新**
   - TrackingManagerにGestureTrackerを統合
   - HandTrackerとGestureTrackerを並行して実行
   - HandTrackerは手の位置情報を提供
   - GestureTrackerはジェスチャー認識を提供

6. **デバッグ機能**
   - 検出したジェスチャーをコンソールに出力
   - ジェスチャー遷移（Victory → その他）の検出をログ出力
   - デバッグ描画機能（オプション）

### 完了条件

- [ ] `src/types/gesture.ts`が作成され、必要な型が定義されている
- [ ] `src/components/camera/GestureTracker.ts`が実装されている
- [ ] TrackingManagerにGestureTrackerが統合されている
- [ ] ピースサイン（Victory）が正しく検出される
- [ ] V閉じ動作（Victory→その他）が正しく検出される
- [ ] 左右の手が独立して認識される
- [ ] ジェスチャーの変化がコンソールに出力される
- [ ] TypeScriptコンパイルエラーがない
- [ ] ビルドが成功する

### 検証方法

1. `pnpm run dev`でアプリを起動
2. ブラウザで画面を開き、カメラを許可
3. 手でピースサインを作る
4. コンソールに「Victory」が検出されたことが表示される
5. ピースから手を閉じる（または他の形にする）動作をする
6. コンソールに「V閉じ動作検出」が表示される
7. 左右の手で別々に認識されることを確認

---

## Step 3.2: 手の3Dモデル表示

### 目的

トラッキングした手の位置に3Dモデル（カニの手）を表示し、ジェスチャーに応じてモデルを切り替えます。

### タスク詳細

1. **型定義の追加**
   - `src/types/scene.ts`に手モデル関連の型を追加
   - 手の状態（開・閉）
   - 手モデルの設定

2. **CrabHandコンポーネントの実装**
   - `src/components/renderer/CrabHand.ts`を作成
   - カニの手の3Dモデル作成（開・閉の2種類）
   - 暫定的にプリミティブ形状で実装:
     - 手のひら部分: 球体
     - ハサミ部分: 円柱×2（開閉可能）
   - ジェスチャーに応じたモデル切り替え
   - 手の位置更新メソッド

3. **2D座標から3D座標への変換**
   - HandTrackerから取得した2D座標（0-1の範囲）を3D空間座標に変換
   - カメラのFOVとアスペクト比を考慮
   - Z座標は固定（カメラから一定距離）
   - 座標変換ユーティリティ関数の実装

4. **GameManagerへの統合**
   - GameManagerにCrabHandインスタンスを2つ追加（左右の手）
   - HandTrackerのコールバックで手の位置を更新
   - GestureRecognizerのコールバックで手の状態を更新

5. **デバッグ機能**
   - 手モデルの表示/非表示切り替え
   - 座標のコンソール出力

### 完了条件

- [ ] `src/components/renderer/CrabHand.ts`が実装されている
- [ ] カニの手モデル（開・閉）が作成されている
- [ ] 手の位置にモデルが表示される
- [ ] トラッキングした手の動きに追従する
- [ ] ピースサインで手が開く
- [ ] V閉じ動作で手が閉じる
- [ ] 左右の手が独立して動作する
- [ ] TypeScriptコンパイルエラーがない
- [ ] ビルドが成功する

### 検証方法

1. `pnpm run dev`でアプリを起動
2. ブラウザで画面を開き、カメラを許可
3. 手を動かすと、画面上にカニの手モデルが表示される
4. 手の動きに追従してモデルが移動する
5. ピースサインでハサミが開く
6. 手を閉じるとハサミが閉じる
7. 両手を同時に動かして、独立して動作することを確認

---

## Step 3.3: ジェスチャーでのロープ切断

### 目的

V閉じ動作時にロープとの当たり判定を行い、ロープを切断できるようにします。

### タスク詳細

1. **当たり判定の実装**
   - V閉じ動作検出時に、手の位置でロープとの当たり判定
   - GameManagerの`cutRopeAtPoint()`を再利用
   - 当たり判定範囲の調整（クリックより少し大きめ）

2. **GameManagerの更新**
   - GestureRecognizerのコールバックを追加
   - V閉じ動作検出時に`cutRopeAtPoint()`を呼び出し
   - 手の3D座標を使用

3. **フィードバックの実装**
   - ロープ切断成功時の視覚的フィードバック
   - スコアアニメーションを手の位置に表示
   - 切断エフェクト（オプション）

4. **クリック操作との共存**
   - クリック操作も残しておく（デバッグ用）
   - 両方の操作方法が同時に機能する

5. **デバッグ機能**
   - 当たり判定範囲の可視化
   - 切断判定のログ出力

### 完了条件

- [ ] V閉じ動作でロープとの当たり判定が実行される
- [ ] 手の位置でロープが切断できる
- [ ] スコアが正しく加算される
- [ ] スコアアニメーションが手の位置に表示される
- [ ] 左右の手でそれぞれ切断できる
- [ ] クリック操作も引き続き機能する
- [ ] TypeScriptコンパイルエラーがない
- [ ] ビルドが成功する

### 検証方法

1. `pnpm run dev`でアプリを起動
2. ブラウザで画面を開き、カメラを許可
3. ロープ付き宝物が出現する
4. 手をロープの位置に持っていく
5. ピースサインを作る
6. 手を閉じる動作をする
7. ロープが切断され、宝物が落下する
8. スコアが加算される
9. 複数のロープで動作することを確認
10. 左右の手でそれぞれ切断できることを確認

---

## 技術メモ

### MediaPipe GestureRecognizerについて

MediaPipeの`GestureRecognizer`は、Hand Landmarkerの上位版で、手のランドマーク検出とジェスチャー認識を同時に行います。

**認識可能なジェスチャー（7種類）:**
- `Victory`: ピースサイン（Vサイン）
- `Closed_Fist`: グー（全指を握る）
- `Open_Palm`: パー（手を開く）
- `Pointing_Up`: 人差し指を立てる
- `Thumb_Up`: サムズアップ
- `Thumb_Down`: サムズダウン
- `ILoveYou`: 親指+人差し指+小指を立てる

**特徴:**
- 事前学習済みモデルで高精度
- ランドマーク座標とジェスチャー名を同時に取得可能
- 複数の手を同時に認識可能
- 各ジェスチャーに信頼度スコア付き

### ジェスチャー判定ロジック

本プロジェクトでは以下の判定を行います:

1. **ピースサイン検出**: `Victory`ジェスチャーが認識された状態
2. **V閉じ動作検出**: `Victory` → `Victory以外`への遷移
   - チョキを閉じた形は事前定義ジェスチャーに含まれない
   - そのため、`Victory`から別の状態（グー、パー、認識なし等）になったら「閉じた」と判定
   - ユーザー体験: ピースから手を閉じる/変形させるとロープ切断

### HandTrackerとGestureTrackerの併用

- **HandTracker**: 手の位置情報（ランドマーク座標）を提供
- **GestureTracker**: ジェスチャー認識（Victory等）を提供
- 両方を並行して実行し、TrackingManagerで統合管理

### 2D→3D座標変換

```typescript
// 2D座標（0-1の範囲）から3D座標への変換
function convertTo3D(x: number, y: number, camera: THREE.Camera): THREE.Vector3 {
  // 正規化デバイス座標に変換（-1 to 1）
  const ndcX = x * 2 - 1;
  const ndcY = -(y * 2 - 1); // Y軸は反転

  // カメラから一定距離の3D座標を計算
  const vector = new THREE.Vector3(ndcX, ndcY, 0.5);
  vector.unproject(camera);

  return vector;
}
```

### パフォーマンスの考慮

- ジェスチャー認識は毎フレーム実行されるため、計算量を最小限に
- 座標変換は必要な時のみ実行
- 3Dモデルはできるだけシンプルに（ポリゴン数を抑える）

---

## Phase 3 完了後の状態

Phase 3が完了すると、以下が実現されます:

- ✅ カメラで手をトラッキング
- ✅ ピースサインとV閉じ動作を認識
- ✅ 手の位置にカニの手3Dモデルが表示
- ✅ ジェスチャーでロープを切断
- ✅ スコアが加算される

次のPhase 4では、UI画面（タイトル、セットアップ、設定、リザルト）を実装します。
